This is a transcript of a lecture by Sachin Rekhi followed by a Question and Answer. The lecture is titled "The Hunt for Product Market Fit"


Sachin Rekhi: So the topic that we discussed covering was something that's near and dear to my heart, which is this idea of the hunt for product market fit. And you know, one of the biggest challenges that I think every startup or really anyone innovating on new products struggles with is building a new product and then finding product market fit for it. And it's this incredibly difficult challenge that, that I've been through many times in my own career and wanted to share kind of some of the lessons I've learned in trying to bring some discipline and some rigor to this process of trying to find product market fit for whatever product you're building. So I'd thought I'd start by telling you a little bit more about my background and, and, and my sort of hunts for product market fit. So I've had the opportunity to found three different startups in my own career, starting with anywhere fm, which was mentioned, which was a web music player that made it super easy for you to take your entire music collection, upload it, and and play it on the web. 
This was in the early days, this was back in 2007, one of the early Y Combinator funded classes. I was actually in the same class as Drew Houseton and Dropbox. Definitely the success of our YC class, but we built anywhere FM before the days of Spotify before the days of all the great music services that we use today. We ended up selling that to another music startup called ime, which ultimately sold to MySpace. MySpace music itself. I then went on to build another startup called Fiera, which was a personalized new news digest that effectively gave you the content that was most interesting to you by actually mining your Twitter feed. So very similar to a product today called Nuzzle, if you guys are familiar with it. But was doing that back in 2009. And as was mentioned, I started a company called Connected, which was a contact management tool. Made it super easy for you to manage all your contacts, aggregating them in one place from your email, your social networks, from your mobile devices, and then also acting as a personal relationship assistant, helping you stay in touch. And that was sold as mentioned to LinkedIn where I spent four years taking that product and integrating it deeply on LinkedIn. 
But I've also had the opportunity to find product market fit in large tech companies. You know, I started my career actually at Microsoft working on Visual Studio and most people know Visual Studio as this tool for application developers to help them build applications on the Microsoft platform. But what we were working on was a new version of Visual Studio helping database developers to be far more productive with Visual Studio. So helping them create schemas, create stored procedures, bringing uni unit testing and refactoring to the database world. So a lot of new novel concepts for for database developers. And so that was kind of exciting to me 'cause I started at a large company like Microsoft where most of my peers were frankly working on like version 12 or 15 of Office or Windows. But I got an opportunity to work on something brand new and actually even at LinkedIn I was doing very much the same. And you know, I worked on this product called Sales Navigator, which was this idea that you could leverage the LinkedIn platform to help sales professionals be far more effective with selling. And we ended up building a a, a product there and eventually selling it to sales professionals and grew the business to hundreds of million in revenue and it's doing quite well these days. And so I've had the opportunity to sort of find product market fit not only in my own startups but in larger tech firms as well. 
And lately as, as was mentioned, I left LinkedIn about six months ago ultimately to take some time off and then eventually to start my next company. But in the meantime, I've actually been advising five early stage startups, all pre-product market fit, all of them have a product in market, but not kind of meeting the team's objectives just yet. So working really closely with them to help them to kind of build and grow. So I wanted to start by talking a little bit about some of the common struggles that I think many of you have felt in sort of the hunt for product market fit, or at least I've felt or, or the teams I'm advising have felt and these things might sort of resonate with you guys. So the first one is this emotional rollercoaster. I think everyone's gone through this when they're working on a new product innovation where last week you get this great tech, you know, press release where people love you reviewing your product, saying it's awesome. 
So you know, you're very excited thinking everyone loves your product and then the next week you get some like really bad review or some customer complaint and now you're like, oh my God, no one loves our product. And so these kind of emotional rollercoasters are so common in sort of this crazy hunt to try to find product market fit. Similarly, there's sort of this case that happens all the time, which is there's lack of precision where, you know, one of your team members might be like, oh my god, it's not working. And you're like, what's not working? And it sort of feels like everything's not working and, and it gets pretty chaotic. And I'd say that, you know, I've seen this so many times at startups and, and sort of a lack of precision on what exactly is not working, but sort of this general sentiment of oh my god, things, things are not working. 
Another really challenging situation is, is the late pivot. Maybe you realize based on what you've been working on, that it's not quite working, it's not quite resonating in the market and you're gonna have to make a substantial pivot and that's fine. That happens all the time. The the challenge is when you get that insight way too late and when you realize, oh my God, we only have two months of funding left for our startup, whether in a smaller company or in a larger company. And now you really gotta hustle to try to figure out are you gonna be able to succeed? All, all too common in, in a lot of startups and, and this one's a sort of insidious one where you have a unclear market, maybe you get incredibly excited early on because you have this incredible set of engaged users that love your product and now all you think you need to do is scale that and you're constantly building more functionality to address the needs of that user base. 
But then six months later you realize uhoh we're kind of in a small market, you know, it turns out those people did love us, but it's not a big enough opportunity to really go after in a big way. And you know, that becomes incredible challenging when you, when you have that learning too late. So all of these things I've talked about are so common when teams are trying to find a product market fit and it's, it's incredibly challenging to do this. That's why these are sort of the norms. But what I wanted to talk about is, is bringing a bit of discipline to the hunt for product market fit. And so does some of the lessons I've learned on how can you bring rigor and discipline to the overall process and, and sort of these are the lessons I've learned doing it myself, but also that I'm constantly applying these days to the companies I'm advising. 
So I'll walk you through this framework that I've developed around this and it'll seem fairly simplistic at first, but then we'll get into the nuances and the details of what this really looks like. And so it's this idea of define, validate and iterate this constant loop that you're going through as you're trying to find product market fit in your startup. And it starts with defining very clearly your product market fit hypothesis. So what is in fact the reasons that you think your startup or your products is gonna win in the market? D delineating that as clearly as possible is, is definitely where you start. Then it's clearly about validating those hypotheses for each of those product market fit hypotheses you've come up with. You know, does it turn out in fact to be true that hypothesis in the market? And ultimately it comes to iterating on those hypotheses whether you've determined more detail on the hypotheses that you've already identified or maybe you need to pivot on them because certain ones turned out not to be true. So this is the high level loop that you're constantly going through to actually find product market fit. And so now I'll talk about each of these in detail and what that looks like when I've seen it done well. 
So as I mentioned, the first phase is really this idea about defining your product market fit hypothesis. So as I said, this is sort of collectively how do you believe you're gonna win? Your product's gonna win or your startup's gonna win? It's collectively sort of your vision and strategy altogether for the product that you're building. And I find the easiest way to do this is to sort of detail this out in these eight different product market fit hypotheses. Every startup has a ton of different hypotheses that they're validating, but I've found that in general most products kind of need to solve each of these eight to be successful. And so you know, it starts with knowing your target audience, walking through the problem you're solving, understanding your value propositions, your strategic differentiation, your competition, your acquisition strategy, your modernization strategy, and your KPIs. And again, we'll go through each of these in detail on what I mean by that. 
And I actually find it incredibly helpful to write these down and I am not talking about some 40 page business plan. I've done this with most of my portfolio companies and it's never more than a one to two page doc. And you know what's fascinating about that exercise is that it's always clarifying for the teams. I think folks always start to believe that, oh we all know this even though it's a small team of maybe five, 10 guys and gals on a single team, that it's clear what these are. But it's been actually pretty illuminating when I've done this exercise to realize that oh actually there was a different assumption between two members of the team on what your acquisition strategy was gonna be. And it's actually very clarifying to, to take the time to get this on paper, to get the time to agree to it and then go from there. So let's talk about specifically what I mean by each of these hypotheses. 
So first one is target audience. So this one should be pretty obvious you're building a product to solve a pain point for someone. This is really the someone who is the target audience that you're building for. The nuance here that I think is important is unfortunately here in the valley, since so many startups are kind of focused on raising funding, investors I think teach us the wrong lessons on what a a target audience statement should look like. Oftentimes what you see is investors are very eager to fund startups that are going after the biggest total addressable market out there. And you know, it's very easy for your investor presentation to have a slide like take sales navigator. There's 20 million sales professionals in the world based on lots of census reports that looks great on an investor slide, but that's a terrible way for a company to be managing their their own startup. 
And so when I talk about target audience, what I mean is think not about that total addressable market, but think about that bullseye. What's the center of the very best customer segment that will love your product and really derive value from it? And so, you know, for us, for example in Sales Navigator, it wasn't that we were going after sales professionals, we very quickly iterated on it to figure out we're really going after B two B sales professionals. And then we went even further to talk about the specific kinds of sales professionals within an organization that we're going after. Typical sales organizations are divided between hunters and farmers. And so we knew our initial sweet spot was hunters and eventually wanted to sort of build it out on farmers. Even within that there's subsets of roles like sales developers, account executives and things like that. And we eventually got to the point where we understood the sweet spot of who was gonna drive the most value out of our solution and then could constantly expand from there. And so that's what I mean by having a tight definition of your target audience. 
The next is, is a deep understanding of the problem you're solving. And so you'll see actually I very clearly divided most of what people think of as the product solution into three distinct parts. The problem you're solving, the value proposition and the strategic differentiation. And I do that for very specific reasons because as you're iterating, you might find, for example, the problem you're solving resonates incredibly well. It just turns out that your value proposition isn't quite there yet or maybe your strategic differentiation isn't there yet. And it's important to understand those nuances so you know when you're iterating what to actually iterate on. And so the problem you're solving is really all about, you know, clearly you're building a solution to solve some problem. What is that problem you're solving? And and ultimately it's about having a detailed understanding of are you building a vitamin or a painkiller? Is the problem faced by your target audience a need to have a must have? That's obviously a painkiller or a nice to have and we'll talk about some of the customer validation techniques you can use to figure that out. 
Then you have the value proposition. And this is not your feature list, this is not your product roadmap. This is simply the value promise that you're giving to your customers on what you're gonna solve for them. And this again, becomes really important to distinguish from your actual solution. So take something like sales navigator again, we were building a tool for sales professionals. The problem we were solving is that sales professionals struggle on a regular basis to find high quality leads and to get people to respond to them when they reach out to them. This whole kind of traditional process of cold calling is incredibly broken because no one likes an outreach from a sales professional when they have no need for the products and services they're selling. And so our value promise was this entire idea that sales navigator would help you to actually find higher quality leads that are more likely to respond to your outreaches. 
So there's no features detailed there, that's just the value promise or the core benefit that we're gonna derive. And what the reason that's important is 'cause you want to understand in validation is that value proposition resonating with your customers independent of your solution. Which obviously then the question becomes, well how are you gonna deliver on these higher quality leads? But it's important to distinguish that so you understand, well do you have a case in which the problem you're solving has resonated with the customer? You have a painkiller problem, you have a value proposition that they're really interested in, and now can you create a solution which is your strategic differentiation that in fact delivers on it? 
And this is really kind of strategic differentiation is what you always consider kind of your core product solution. And, and the thing I'd say here is you really need to aspire to an incredibly high bar, which is how is your solution 10 times better than all the other solutions out there in the marketplace? And the reason that's important is because it just turns out there's incredible inertia to changing your existing solutions in the marketplace. So you have to have something so compelling that you're gonna convince people to move away from whatever they're doing right now. Similarly, you have to understand the competition and how is your solution better than the direct competitors? But also when you're talking about other cases, like when you're in a new market, you're not gonna have direct competitors, but we're gonna have is some alternatives, which is they're doing some existing process within their team and they're interested in looking for new ways to actually make that happen. And so you wanna understand how is the workflow you're enabling very different than what they're already doing. 
Alright, so acquisition strategy is kind of very well understood these days. When you build something, they will not come automatically. You have to find great ways to acquire those users. So what are the primary ways you're gonna find and attract customers is sort of the beginning of this. But when you get into the details of this, what this really comes down to is how are you gonna cost effectively acquire users? And ultimately what this comes down to, especially for SaaS-based businesses is sort of a CAC versus L T V calculation. And so you're constantly increasing the refinement on how you're actually gonna drive acquisition for your users. And then you have modernization. What are the primary and secondary ways that you're gonna actually be able to monetize your product offering? Once you get in the do the details and nuance here, it's really about is there strong willingness to pay? And what is that willingness to pay? Because that will ultimately detail what your pricing strategy ends up being. 
And finally it's defining your KPIs. So what are the north star metrics that are incredibly important for you to actually know upfront? And I always encourage people to detail this right from the beginning because you should be using as the constant barometer of how you're doing as these KPIs to help avoid the rollercoasters. So when you're asking yourselves how are we doing? Are we making progress towards our mission and our, and our vision and our goals, you can simply reflect back on this and not allow specific anecdotes or point in time feedback to really sort of take you away from what you're ultimately achieving. 
All right, so we talked about the eight different dimensions that make up your key product market fit hypotheses. The, the biggest feedback I'd give you on that is, is this statement here, which is minimize your dimensions of innovation. So at first blush, some people find this, you know, kind of surprising we're, we're in the business of innovating and and building startups and really trying to push the envelope. But it turns out when I've seen this work incredibly well, what you've done is you've picked very specific dimensions of innovation that you're innovating on. And for the rest of them you're leveraging best practices. So let, let me make this real. So the idea here is that let's say you've decided you're in an existing product market category and you've built a better mousetrap, you've built a better product that just the value that you're actually able to drive is just better. 
In that case, what you really want to do is for all of these other dimensions, figure out the best practices of what are the best people doing along those dimensions. You know, how you're innovating is strategic differentiation and not along these other dimensions. And so this becomes really important because as a small startup or a small team with limited resources, you can't innovate on all of these things. It's gonna be incredibly difficult. Instead you should pick and clearly know what are your points of differentiation and where are you gonna leverage best practices. And so this point of leveraging best practices is also incredibly hard. It's almost as hard as innovating because what you need to do is understand what are the most successful companies in your category doing that you can replicate. So for example, maybe you realize that there's this com, there's this company that you have a better product compared to them, but you really want to understand in a detailed way what is their acquisition strategy. 
But somehow they've amassed, you know, millions of customers or a material revenue line and now you need to study and really understand how you can leverage their best practices to be successful. And so what I've often seen is folks are innovating on any one of these dimensions, any couple of these dimensions, but folks that are literally saying that I'm building a product targeting at a different audience compared to what it the traditional incumbents are going after. You know, we're going in with a very different value proposition. Our strategic differentiation's very different. Oh, and also we're innovating on the entire acquisition strategy and we're monetizing in a brand new way. You're setting yourself up for failure when you're attempting to do all of that. So be clear with your teams on what dimensions you're innovating on and which ones you're leveraging best practices. 
Alright, so now we talked about the define phase. Now you start to begin that loop of validating. And so the thing I always encourage folks to do is to start by saying, out of these eight product market fit hypotheses, which of the ones that are most uncertain, which are the ones that we really want to invest early on spending our time on, because those are the ones that are gonna make or break our business on whether we can figure them out or not. That usually looks like the areas of innovation, the subset of things that you've decided are the areas you're gonna innovate on. And what you want to do is develop a process that enables you to test those things first. Because if you're simply testing the things that are more likely to succeed, then you're not really getting at the root challenge that you're gonna face in that startup. And so getting to an agreement on what are those pieces that are the most uncertain and start your validation there. 
So when it comes to validation, there's a million ways to actually validate. I certainly don't have to tell you guys this, but what I generally lump it into kind of these two broad categories, which is pre-product and post-product, pre-product, you're using a ton of customer validation interview techniques that you can leverage to actually get feedback from potential customers and potential users on your product and the experience that you're designing. And then ultimately post products, you actually have some real users. So now you can use customer metrics to actually get validated learning from that. And so I'll talk a little bit about kind of some of the best practices across both of these dimensions. So I'd say the first one with customer validation interviews, the key thing to remember with customer validation interviews is you don't have the luxury that you do with quantitative metrics when you have at scale. 
There's no statistical significance when you get into customer interviews and customer validation. And so you're gonna have very few data points that you're using that you're gonna base material decisions on. And what you wanna do is what, what comes from the most value from customer interviews is this concept of synthesis, which it's not any one anecdote that you hear from a customer that's really gonna actually help you figure out the direction of the business. But it's the repeated anecdotes that create a pattern that you can use as learning for direction of where you wanna take the business. And so that's where the actual validation techniques you're using become incredibly important to ensure you're setting yourself up for synthesis. So you know, when it comes to customer validation, the number one feedback I think you'll hear a million times is get outta the room, talk to customers. 
You know, exposure hours are incredibly important. The more time you're spending talking to your potential customers is really important. That being said, I've found that a very specific set of techniques can help to allow you to glean the most amount of information when you're actually having those customer conversations. And it starts simply by having an interview guide or a interview deck. And the reason this is important again, is you're gonna have very few interview conversations. You want to ensure that the conversations you're having can be synthesized across conversations and the questions need to be asked in the same way. And so what I've always done is have an interview deck where we're kind of walking through the set of questions we want to ask them and making sure whoever's doing the interviews is asking them the exact same way so you can get that syn synthesis property that you really want across your interviews. 
Similarly, what I've done is usually conduct these in successive waves. So let's say you're starting out and you're doing very high level validation, so really taking those product market fit hypotheses and you're at the phase of does my customer even resonate with the problem that I'm trying to solve? So then you do these successive waves, so let's talk to five customers, see what they say, and then you iterate on it and then you're constantly changing your validation deck based on what you're learning on each wave. So you're getting that learning and you're incorporating that learning as quickly as possible. Similarly, I find it most effective to do one-on-one interviews as opposed to group interviews. Again, because you have so few data points, you wanna make sure you're getting independent data points and you're avoiding sort of some of the group think challenges that you have when in a group setting. 
I also find it really helpful to do both aided and unaided questions. So what do I mean by that? In in the specific case of when you're trying to assess whether the problem you're solving is a vitamin or painkiller, you know, we would go to customers and talk to them and say, Hey, what's the most painful aspect of the sales prospecting workflow for you? Completely unaided trying to get from their head what are the things that they struggle with? And then putting up a list of five different aided problem statements and seeing if any of those specifically resonate with them. And then having them rank the list of aided against even their list that they provided to get a sense for, okay, we were really going after number three in our aided list, they came up with five other things that were far more important to them. 
That's a clear signal that you likely have a nice to have not a need to have. And that becomes really important to get those, that understanding. And that's the the key piece here. The the, the challenge I've seen with some folks when they do these interviews is everything you ask needs to be relative. You know, when you ask someone like, is this important to you? You know, it's very easy to get feedback like yeah or like, sure, yeah, that yeah that's important but that's not interesting or that's not gonna be very helpful for you. Instead it's always relative prioritization against something else, against their other priorities, against the other solutions that they're using. That's what helps you get clean signals on whether you're in fact disrupting existing solutions, solving a pain point that's really important to them or not. And so those are just some of my tips on kind of customer validation interviews. You know, I've written a blog post that goes into detail on you know, how to structure customer validation decks and what I've seen works for a lot of teams and so we've implemented this in a bunch of the companies that I've been advising and it's really helped them to get the most bang for their buck in the conversations that they're having with customers on a regular basis. 
Alright, 
So you know, once you move to actually having a product, whether it's a beta, alpha or anything that's in front of your customers now you can clearly move to the, the more classic phase of customer metrics. And here I think, you know, a lot of the typical lessons apply, what you wanna figure out are what are the key acquisition engagement, monetization metrics that best tell the story of how people are resonating with your product. You know, how are you acquiring customers and are people actually being acquired appropriately? Are they engaging with it regularly? Are you retaining those users and are you able to monetize it? So I think that there's been kind of a lot written about those classic metrics, but what I'd say is important is to go above and beyond that and think about these additional metrics. So for example, let's say your acquisition strategy is about using a sales team to go promote your product to a key audience. 
You know, at that point you really want to detail and understand the sales funnel metrics because that's a key assumption that you need to be verifying and validating is in fact working or not. And making sure you have metrics for all aspects of your key hypothesis becomes really important. You know, one that we used heavily at LinkedIn was net promoter score. Obviously you could tell if people were engaging with the pro, but are they really delighted by the solution that we're building? And we were doing quarterly assessments of net promoter score and had even goal net promoter scores that we were looking to achieve for each of our quarterly goals. Maybe it's customer service experience and metrics around that and satisfaction on that process if you're really trying to differentiate based on your customer service. So figuring out what the right metrics are for your entire product experience, not just the product. 
So the hardest part of this is figuring out what constitutes good knowing, for example, that one third of your users download your iPhone app but never activate is that good or not? And really this is the hardest part 'cause you need to establish benchmarks for each of your key metrics. Otherwise just knowing the number frankly isn't that interesting. What's challenging about this is that a lot of those benchmarks are proprietary companies don't give out their sort of activation rates, their engagement rates, their monetization rates. And so this is like my best advice here frankly is beg, borrow and steal to get those comps. And this is where, you know, it becomes incredibly important to know how well you're doing, but there's really no shortcut for trying to figure out what good looks like looking at other apps and what they're doing for each of their key metrics and figuring out what those comps look like. So definitely the hardest part of that process. So, you know, I kind of talked about this pre-product phase and post-product phase, but it turns out this is constantly an iterative cycle. You know, once you have a product in market, yes you have customer metrics, but as you're building new features, you're, you again return to the pre-product phase of validation. So it's a constant loop of iterating between customer validation and customer metrics to really validate each of those hypotheses. 
Alright, all right, so now we've conducted a bunch of validation, now it's time to iterate. And so I think, you know, one of the, the key things I like to call out on the iteration phase is this concept of what does iteration mean? And in my mind it means either increasing precision or changing a hypothesis. So this might sound simple, but I, I actually find a lot of teams think about iteration as changing hypotheses. They think, okay, I validated it worked, I was correct, I don't need to change it, so we're good. But actually most of the time what you're gonna be doing is increasing precision. So what do I mean by that? Let's go back to the target audience. Like we may have started sales navigator thinking we're going after sales professionals, but then as we learned what pain points we could really solve, we realized we were going after B two B sales professionals. 
And then as we got far more nuanced about it, we really started to understand the people that we can make the most impact on were account executives and and sales dev teams. And so you're constantly increasing the precision of your understanding about that hypothesis and frankly, most of your validation time should be spent doing that. Similar for acquisition strategy, maybe you've realized that you really wanna use content marketing to build awareness for your product, or maybe you realize you want to use paid marketing and figure out the channels that are gonna work for you. But as you iterate, you get more information, maybe you've figured out what is sort of a C P L that you're able to get on a per lead basis if you're using something like paid marketing or maybe on the content marketing side you're increasing precision by really understanding, you know, what kind of traffic you're generating back to your product on a per, you know, blog post basis. 
So that's what most of your time is spent on is increasing precision as as you're validating. That being said, of course there are gonna be cases, especially early on when you're changing your hypothesis and that obviously occurs when you've realized, you know, what, what you initially said isn't quite resonating and now it's time to change it. So I wanted to share kind of a few other things I've run into along this iteration phase. So, you know, you think startups have this great luxury that they can move faster than large companies and oftentimes they can. But actually, you know, when I go through this, this process with folks, what's fascinating is what actually causes teams to slow down on going through this loop of define validating and it iterating. The number one thing I'd say is the speed of decision and the speed of decision making. 
And so the thing that's important here is that you need to make sure that in your small team there's clear decision rights that have been set. So this obviously is really important in large companies when you have a lot of stakeholders, you have a lot of people in the room, a lot of cooks in the kitchen, and you gotta figure out who owns this decision, who gets to make this call on whether we're gonna go this way or that way. Is it an individual? Is it a group of individuals who has those decision rights? But actually it turns out it's equally important in small teams. And the reason I say that is like, maybe there's only five people in the room, so it seems like it should be really easy to make decisions, but it turns out what's fascinating, especially with startups at the earliest team, you got those five people in the room to take this risk to work on this really compelling new, exciting, innovative problem because they wanted to have a strong voice in the early stages of building on a solution that matters. 
And actually what becomes important is that it's clear when you get this feedback from your validation which direction we're gonna move in. And having clear decision rights on who owns what set of decisions makes it in infinitesimally faster to iterate. And so, I mean it could just be a a a quick agreement between the team on like, when we run into questions on which way we're gonna go, there's folks that might own the technical decisions, there might be folks that own the product decisions, there might be folks that own the design decisions, just making that clear. So you know that that's gonna enable you to improve the speed of iteration because often where people get stuck is you've gotten a bunch of feedback and it turns out because you've got such weak signals on customer validation, you could interpret that feedback a million ways and smart people are going to disagree and that's a good thing. 
And, and then it becomes important to be able to coalesce on a, on a decision and move on. And that speed of your ability to do that is really gonna make a huge difference on how fast the team can move. But the key thing I have to remind folks is that it's no shortcut for building shared contact. What do I mean by that? Okay, you've identified your decision maker, they get, they hear the feedback and then they quickly make a call and like, okay, we're going in this direction. That is also not an effective way to, to really kind of run a team and, and be successful. And what you constantly need to be doing when you have that authority and that obligation of making decisions that you're driving buy-in from the team, the team feels as if they have a clear understanding and ownership and buy-in of, you know, how that decision was arrived at, was keeping the team incredibly motivated is incredibly important. And so this is where, you know, it, it's, it's sort of nuanced and challenging where it's not as simple as assigning owners and let, letting them make the call, but ensuring along the way people are constantly bought off on why the decisions were made, why there was a pivot or change and why you're moving in that new direction. So kind of an important tip I've seen that even small teams struggle with because it's not very clear who owns those decisions. 
The other thing I'd say is it's equally important to pivot on a single hypothesis. And, and the reason that is, is that just because something's not working, you know, it really doesn't mean that everything's not working. And this is where when you get to that precision of like, okay, it turns out our problem is resonating, our value proposition's resonating, it just turns out our actual solution doesn't deliver on that value proposition. Now, you know, the bounds of the iteration that you need to do is simply around improving the product to deliver on that value proposition. That becomes important language that you want to even use internally so you have a deep understanding of what does it's not working really mean. And then just pivot on on one of more of these dimensions. 'cause when you attempt to pivot on everything or multiple dimensions at once, it becomes very difficult to get validated learning on whether in fact what you thought was not working is now working with your new iteration. 
And so that becomes really important to pick a single hypothesis and to be clear on as we're iterating, we've learned that this piece doesn't work and now we're moving this direction. And I think what you'll find with, with, with most of what I'm saying is this stuff isn't rocket science. A lot of it is is fairly intuitive, but actually when you're moving incredibly fast trying to make decisions, build a compelling product quickly, it's very easy to skip over these phases or to skip over that precision on what's working versus not. But it actually makes of a world of difference in your ability to move in the right direction versus not. 
It is also helpful to distinguish kind of your prioritization on what you're trying to learn. So what are your first order or second order problems? So for example, like you know, you have a debate on should we be investing more in kind of the core product or be investing more in acquisition strategy? What turns out your first order problem is always can you make something people want? And then sort of a second order problem, which is still incredibly important, is can you drive traffic and, and build acquire users for that solution? But being clear about what those first order problems are and second order problems are when it comes to startups. The the big thing that also comes to mind, especially here in the valley, is what actually do you need to prove to get your next round of funding? And that's actually a really important discussion that that is valuable to have with your investors because let's say you've raised a couple million bucks as a seed round of funding and you're going in for your series A, making sure you're working on the things that you need to prove to be able to get that series A and having a shared understanding of it actually becomes fairly important. 
So being clear of what phase you're at is, is fairly important. 
All right, so you know, we talked about this loop of this define, validate and iterate a very simple loop that you know, helps you to bring a little bit of rigor and structure to the, the process of finding product market fit. And as I mentioned, I've been rolling this out now with a bunch of companies I'm advising and it's been very helpful to, to document those product market fit hypotheses to describe in detail what they're changing and what they're learning as they make those changes. And it makes the conversation far more rigorous and, and takes a little bit of that turmoil that you constantly see with the rollercoaster ride, with the kind of lack of precision out of out of it. That being said, this is no silver bullet, this is no holy grail, this just adds a little bit of rigor to the process. It's still incredibly difficult to find new innovative solutions and you know, that's, that's kinda the tall order that all of us have as as product creators. But I hope this helps a bit to create a little bit of process around it. So wanted to open it up to see if you guys have any questions about any of this or kind of any, any thoughts at all. 

Guest Question: Yeah, so as alluded to science, but the difficulty of, it's when you're in a problem you can get kind of, you take a step back and say, am I thinking about the right thing or am I asking the right questions? So do you have any strategies for ways that you make sure that you remember to take a step back to ask those questions and refocus? 

Sachin Rekhi: Great question. I think you kind of hit the nail on it, which is it's often very difficult to kind of turn this into a process that you would use when you're so incredibly busy actually working on your own startup. You know, I find it's incredibly important to create forcing functions. So obviously I've done this both at scale and smaller startups at scale, at LinkedIn what we used was a quarterly O K R process, which is a goal setting framework that enabled us to be very clear every quarter when we're going into the quarter, what are the goals that we're trying to achieve, what are the key metrics that we're trying to solve for and are we headed in the right direction? And it doesn't need to be as heavyweight as a, as a full on O K R process, but I actually think it's very important to come up with milestones for yourself internally on iterations. 
Maybe it's monthly, maybe it's even faster than that. Where, where the team is getting together looking at what they thought they would achieve in that time period and how they're doing against it. And literally to the point of having a scheduled monthly meeting on the calendar where all the key stakeholders get together and review that. That sort of high level progress report, like I said, it doesn't have to be that that sophisticated, but creating that forcing function of having a regular meeting could be sort of the way that you take that step back and look at how we're doing overall. 

Guest Question: Yeah. What are characteristics of teams that make decisions faster in a kind of context? 

Sachin Rekhi: Yeah, great question on, you know, what makes decision making really work and what those characteristics look like? So I'd say there's a couple of key things. First I said as I mentioned, decision rights is inclu incredibly important. And I think that the fallacy that a lot of folks have is that a decision making process that has a clear owner might not motivate folks to be participating in that process. But actually I find it to be exactly the opposite. When there's a clear owner and a clear decision rights, then it makes it a lot faster to move and it can be very rewarding and motivating for folks to be part of that team if the actual decision making process is really important, is really well understood. So another couple of key dimensions there is make sure whoever owns that decision sees themself as the curator of decisions and ideas, not the owner or the creator of those ideas. 
And so creating a process where ideas can bubble up from anywhere and making sure they feel as if they're heard by the appropriate stakeholders and there's a process for them to be heard becomes really important for people to constantly feel like there's buy-in. I think it's also becomes really important to then communicate decisions on a regular basis. So, you know, GOCO at Square recently gave a great talk on how they have a email alias at Square that they actually send out every major decision to, they send out in detail, you know, the decision meeting, who these stakeholders were, who was the owner, the the, the different alternatives considered the, the ultimate decision that they decided on and the rationale for doing so. And this is an email alias that anyone in the entire company can subscribe to. And obviously they don't do this on every little decision like a, like a UI decision, but they do it on major strategic decisions like roadmaps, like you know, competitive strategy and those kinds of things. 
And that creates a level of transparency which actually significantly helps to actually improve the overall process. 'cause I find the biggest issue you, you face with decision making is stakeholders who feel as if they don't understand the process, they don't understand how they get involved with that process and they don't understand how decisions are made. And so making it easy for folks to be able to get access to that, I think becomes really important. I also think it becomes really important to define when you allow yourself to revisit decisions. And so this becomes important because you often find that you might have decided something and then you're, you're everyone's sort of asking themselves, did we make the right call? Did we or should we change? Or like, should we revisit that decision? And I think you want to clearly establish what are the rules for revisiting a decision. 
'cause if you're constantly revisiting decisions, you're not moving forward. And, and you know, the, the, the lightweight rule I like to use is what new information have we gathered that allows us to iterate or suggest we might wanna make a different call if it's simply revisiting the information we already had or talking through again the research that we've already done. I think that ends up being a poor reason to revisit a decision. But if you're getting this really loud signal that, oh my God, you're headed, there's new information suggesting that maybe that was the wrong call, now it's time to revisit and sort of as people have questions and doubts, you know, what I used to do on my teams is ask, you know, what's the new information that we've learned that might cause us to revisit the decision and sort of creates a precision amongst team members. 
Let's just not revisit for revisiting sake. Let's revisit when we have something new and novel that might suggest we need to change. Because you will often be wrong when you're making decisions quickly and that's fine as long as you're building upon this framework of moving in the right direction and then constantly iterating on top of it. So I think those are some of the things that I've seen to sort of scale decision making. And you know, I think I've learned most of these lessons at scale at these larger companies when there's so many stakeholders that you need a little bit of process to not go crazy. But I find it equally valuable in small teams of even like five, 10 guys and gals to actually be able to use these same lessons. Alright, cool. So thanks guys. I hope this was helpful. 
Thank you.
